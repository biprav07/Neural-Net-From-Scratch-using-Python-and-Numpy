# Neural-Net-From-Scratch-using-Python-and-Numpy
# Neural Network From Scratch ðŸ§ 

This project implements a basic feedforward neural network using only NumPy. It supports training on simple datasets and helps understand the fundamentals of forward and backward propagation. It runs on a simple XOR Dataset which makes it easy for this to be learned for the feed forward layers and is pretty straighforward when it comes to Dimensionality of the Network . 

Similar Approaches can be taken for the MNSIT Dataset which is pretty popular when trying to build such models for scratch but ever since that 3blue1brown video that dataset has lost it's charm on me (Pretty Common) . So that is why I opted for this and also since XOR is a classic non linear classification task (PS : I am a ECE Undergrad too ).

## Features

- Custom layers (Dense/Fully connected)
- Activation functions: ReLU, Sigmoid
- Loss function: Mean Squared Error
- Backpropagation with gradient descent
- No external ML libraries used

## How to Run

```bash
python main.py
